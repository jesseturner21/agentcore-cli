{{#if (eq modelProvider "Bedrock")}}
from langchain_aws import ChatBedrock

# Uses global inference profile for Claude Sonnet 4.5
# https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html
MODEL_ID = "global.anthropic.claude-sonnet-4-5-20250929-v1:0"


def load_model() -> ChatBedrock:
    """Get Bedrock model client using IAM credentials."""
    return ChatBedrock(model_id=MODEL_ID)
{{/if}}
{{#if (eq modelProvider "Anthropic")}}
import os
from langchain_anthropic import ChatAnthropic
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Run via 'agentcore dev' to load agentcore/.env"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> ChatAnthropic:
    """Get authenticated Anthropic model client."""
    return ChatAnthropic(
        model="claude-sonnet-4-5-20250929",
        api_key=_get_api_key()
    )
{{/if}}
{{#if (eq modelProvider "OpenAI")}}
import os
from langchain_openai import ChatOpenAI
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Run via 'agentcore dev' to load agentcore/.env"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> ChatOpenAI:
    """Get authenticated OpenAI model client."""
    return ChatOpenAI(
        model="gpt-4o",
        api_key=_get_api_key()
    )
{{/if}}
{{#if (eq modelProvider "Gemini")}}
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Run via 'agentcore dev' to load agentcore/.env"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> ChatGoogleGenerativeAI:
    """Get authenticated Gemini model client."""
    return ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        api_key=_get_api_key()
    )
{{/if}}
